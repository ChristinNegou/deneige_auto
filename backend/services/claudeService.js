/**
 * Service Claude pour l'assistant IA
 * Int√©gration avec l'API Anthropic Claude
 */

const Anthropic = require('@anthropic-ai/sdk');
const { getSystemPrompt, buildUserContext } = require('../config/aiPrompts');

// Client Anthropic (initialis√© seulement si la cl√© API est pr√©sente)
let client = null;

/**
 * Initialise le client Anthropic
 * @returns {Anthropic|null} Instance du client ou null si non configur√©
 */
const initAnthropicClient = () => {
    if (client) {
        return client;
    }

    const apiKey = process.env.ANTHROPIC_API_KEY;

    if (!apiKey) {
        console.warn('‚ö†Ô∏è ANTHROPIC_API_KEY non configur√©e. Fonctionnalit√©s IA d√©sactiv√©es.');
        return null;
    }

    try {
        client = new Anthropic({
            apiKey: apiKey
        });
        console.log('‚úÖ Client Anthropic initialis√© avec succ√®s');
        return client;
    } catch (error) {
        console.error('‚ùå Erreur initialisation Anthropic:', error.message);
        return null;
    }
};

/**
 * G√©n√®re une r√©ponse IA avec Claude
 * @param {Array} messages - Historique des messages [{role: 'user'|'assistant', content: string}]
 * @param {Object} userContext - Contexte utilisateur (v√©hicules, r√©servations, etc.)
 * @param {Object} options - Options de g√©n√©ration
 * @returns {Promise<Object>} R√©sultat de la g√©n√©ration
 */
const generateResponse = async (messages, userContext = {}, options = {}) => {
    const anthropicClient = initAnthropicClient();

    // Mode d√©veloppement: r√©ponse simul√©e si Claude n'est pas configur√©
    if (!anthropicClient) {
        console.log('='.repeat(50));
        console.log('ü§ñ MODE D√âVELOPPEMENT - R√©ponse IA simul√©e');
        console.log('='.repeat(50));

        return {
            success: true,
            simulated: true,
            response: "Je suis l'assistant D√©neige Auto. Je suis actuellement en mode simulation car l'API Claude n'est pas configur√©e. Comment puis-je vous aider?",
            usage: { inputTokens: 0, outputTokens: 0 }
        };
    }

    try {
        const model = options.model || process.env.AI_CHAT_MODEL || 'claude-sonnet-4-20250514';
        const maxTokens = options.maxTokens || parseInt(process.env.AI_CHAT_MAX_TOKENS) || 1024;

        // Construire le prompt syst√®me avec le contexte utilisateur
        const systemPrompt = getSystemPrompt(userContext);

        const response = await anthropicClient.messages.create({
            model: model,
            max_tokens: maxTokens,
            system: systemPrompt,
            messages: messages.map(msg => ({
                role: msg.role,
                content: msg.content
            }))
        });

        const responseText = response.content[0].text;

        console.log(`‚úÖ R√©ponse Claude g√©n√©r√©e (${response.usage.input_tokens} in, ${response.usage.output_tokens} out)`);

        return {
            success: true,
            simulated: false,
            response: responseText,
            usage: {
                inputTokens: response.usage.input_tokens,
                outputTokens: response.usage.output_tokens
            },
            stopReason: response.stop_reason
        };
    } catch (error) {
        console.error('‚ùå Erreur Claude API:', error.message);

        // Gestion des erreurs sp√©cifiques Anthropic
        if (error.status === 401) {
            return {
                success: false,
                error: 'Cl√© API invalide',
                code: 'INVALID_API_KEY'
            };
        }

        if (error.status === 429) {
            return {
                success: false,
                error: 'Limite de requ√™tes atteinte. Veuillez r√©essayer dans quelques instants.',
                code: 'RATE_LIMITED'
            };
        }

        if (error.status === 529) {
            return {
                success: false,
                error: 'Service temporairement surcharg√©. Veuillez r√©essayer.',
                code: 'OVERLOADED'
            };
        }

        return {
            success: false,
            error: 'Erreur lors de la g√©n√©ration de la r√©ponse',
            code: 'GENERATION_ERROR',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        };
    }
};

/**
 * G√©n√®re une r√©ponse en streaming
 * @param {Array} messages - Historique des messages
 * @param {Object} userContext - Contexte utilisateur
 * @param {Function} onChunk - Callback pour chaque chunk re√ßu
 * @param {Object} options - Options de g√©n√©ration
 * @returns {Promise<Object>} R√©sultat final
 */
const generateStreamingResponse = async (messages, userContext = {}, onChunk, options = {}) => {
    const anthropicClient = initAnthropicClient();

    if (!anthropicClient) {
        // Mode simulation pour le streaming
        const simulatedResponse = "Je suis l'assistant D√©neige Auto en mode simulation.";
        for (const char of simulatedResponse) {
            onChunk(char);
            await new Promise(resolve => setTimeout(resolve, 20));
        }

        return {
            success: true,
            simulated: true,
            response: simulatedResponse,
            usage: { inputTokens: 0, outputTokens: 0 }
        };
    }

    try {
        const model = options.model || process.env.AI_CHAT_MODEL || 'claude-sonnet-4-20250514';
        const maxTokens = options.maxTokens || parseInt(process.env.AI_CHAT_MAX_TOKENS) || 1024;
        const systemPrompt = getSystemPrompt(userContext);

        let fullResponse = '';
        let usage = { inputTokens: 0, outputTokens: 0 };

        const stream = anthropicClient.messages.stream({
            model: model,
            max_tokens: maxTokens,
            system: systemPrompt,
            messages: messages.map(msg => ({
                role: msg.role,
                content: msg.content
            }))
        });

        for await (const event of stream) {
            if (event.type === 'content_block_delta' && event.delta.type === 'text_delta') {
                const text = event.delta.text;
                fullResponse += text;
                onChunk(text);
            }

            if (event.type === 'message_delta' && event.usage) {
                usage.outputTokens = event.usage.output_tokens;
            }

            if (event.type === 'message_start' && event.message?.usage) {
                usage.inputTokens = event.message.usage.input_tokens;
            }
        }

        console.log(`‚úÖ Streaming Claude termin√© (${usage.inputTokens} in, ${usage.outputTokens} out)`);

        return {
            success: true,
            simulated: false,
            response: fullResponse,
            usage: usage
        };
    } catch (error) {
        console.error('‚ùå Erreur streaming Claude:', error.message);

        return {
            success: false,
            error: 'Erreur lors du streaming de la r√©ponse',
            code: 'STREAMING_ERROR',
            details: process.env.NODE_ENV === 'development' ? error.message : undefined
        };
    }
};

/**
 * V√©rifie si Claude est correctement configur√©
 * @returns {boolean} True si configur√©
 */
const isClaudeConfigured = () => {
    return !!process.env.ANTHROPIC_API_KEY;
};

/**
 * V√©rifie si les fonctionnalit√©s IA sont activ√©es
 * @returns {boolean} True si activ√©
 */
const isAIEnabled = () => {
    const enabled = process.env.AI_CHAT_ENABLED;
    return enabled === 'true' || enabled === '1';
};

module.exports = {
    initAnthropicClient,
    generateResponse,
    generateStreamingResponse,
    isClaudeConfigured,
    isAIEnabled
};
